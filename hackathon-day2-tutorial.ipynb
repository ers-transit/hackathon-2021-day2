{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Welcome to the Eureka! tutorial - today we will learn how to run Eureka!'s S3 data reduction module, which takes 2D JWST data and reduces it to 1D spectra.\n",
    "\n",
    "Eureka! is an open-source python package \n",
    "\n",
    "## Goals\n",
    "- walk through all the major steps in data reduction\n",
    "- get comfortable with the Eureka! structure and syntax\n",
    "- most importantly, make sure none of the steps are a black box."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import standard python packages and Eureka!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, time                                                            \n",
    "import numpy as np                                                              \n",
    "from importlib import reload                                                    \n",
    "import eureka.S3_data_reduction.s3_reduce as s3                                 \n",
    "from eureka.lib import readECF as rd                                            \n",
    "from eureka.lib import logedit                                                  \n",
    "from eureka.lib import readECF as rd                                            \n",
    "from eureka.lib import manageevent as me                                        \n",
    "from eureka.S3_data_reduction import optspex                                    \n",
    "from eureka.lib import astropytable                                             \n",
    "from eureka.lib import util                                                     \n",
    "from eureka.S3_data_reduction import plots_s3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0: Initialization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starts timer to monitor how long data reduction takes\n",
    "t0      = time.time()\n",
    "\n",
    "# Names the event (has to match the event name used for the *.pcf files)\n",
    "eventlabel = 'wasp43b'                                                          \n",
    "                                                                                \n",
    "# Initialize metadata object to store all extra information \n",
    "# related to the event and the data reduction \n",
    "\n",
    "meta              = s3.Metadata()                                                 \n",
    "meta.eventlabel   = eventlabel                                                    \n",
    "                                                                                \n",
    "# Initialize data object to store 2D data from the observation                                                       \n",
    "dat              = s3.Data()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try printing out the time by typing ``print(t0)`` in a code cell. Run it again. Do you see the time change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Eureka! control file and store values in Metadata object                    \n",
    "ecffile = 'S3_' + eventlabel + '.ecf'                                           \n",
    "ecf     = rd.read_ecf(ecffile)                                                  \n",
    "rd.store_ecf(meta, ecf)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ECF (\"Eureka control file\") is now stored in a Metadata object. This includes all the high level information about the data reduction (which JWST instrument was used? do we want to display plots? where is the data stored? what size is the extraction window? etc.)\n",
    "\n",
    "To see the current contents of the Metadata object, type ``meta.__dict__.keys``. \n",
    "\n",
    "What is the value of ``meta.bg_deg``? Can you change it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Make directories to store reduced data, create log file, read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Stage 3 Reduction\n",
      "\n",
      "Found 21 data file(s) ending in calints.fits\n"
     ]
    }
   ],
   "source": [
    "# Create directories for Stage 3 processing                                     \n",
    "datetime= time.strftime('%Y-%m-%d_%H-%M-%S')                                    \n",
    "meta.workdir = 'S3_' + datetime + '_' + meta.eventlabel                             \n",
    "if not os.path.exists(md.workdir):                                              \n",
    "    os.makedirs(meta.workdir)                                                     \n",
    "if not os.path.exists(meta.workdir+\"/figs\"):                                      \n",
    "    os.makedirs(meta.workdir+\"/figs\")                                             \n",
    "                                                                                \n",
    "# Load instrument module                                                        \n",
    "exec('from eureka.S3_data_reduction import ' + meta.inst + ' as inst', globals()) \n",
    "reload(inst)                                                                    \n",
    "                                                                                \n",
    "# Open new log file                                                             \n",
    "meta.logname  = './'+meta.workdir + '/S3_' + meta.eventlabel + \".log\"                 \n",
    "log         = logedit.Logedit(meta.logname)                                       \n",
    "log.writelog(\"\\nStarting Stage 3 Reduction\")                                    \n",
    "                                                                                \n",
    "# Create list of file segments                                                  \n",
    "meta = util.readfiles(meta)                                                         \n",
    "num_data_files = len(meta.segment_list)                                           \n",
    "log.writelog(f'\\nFound {num_data_files} data file(s) ending in {meta.suffix}.fits')\n",
    "                                                                                \n",
    "stdspec = np.array([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Important check!* Were the correct files read in? They are stored in ``meta.segment_list``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: read the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file 18 of 21\n"
     ]
    }
   ],
   "source": [
    "# pick a single file to read and reduce as a test\n",
    "m = 17\n",
    "\n",
    "# Read in data frame and header                                             \n",
    "log.writelog(f'Reading file {m+1} of {num_data_files}')                     \n",
    "dat = inst.read(meta.segment_list[m], dat, returnHdr=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What data are we using?\n",
    "\n",
    "The full description of the data is available [here](https://stsci.app.box.com/s/8r6kqh9m53jkwkff0scmed6zx42g307e/file/804595804746)). To quickly summarize, we are using simulated NIRCam grism time series data from the ERS Simulated Spectra Team.  The simulation assumes a WASP-43 b-like planet with physically realistic spectral features added. The simulated data are based on the following observational design:\n",
    "\n",
    "- GRISMR+F322W2 pupil and filter\n",
    "- RAPID readout mode\n",
    "- 19 Groups per integrations\n",
    "- 1287 integrations\n",
    "- 1 Exposure\n",
    "- 4 Output amplifiers\n",
    "The data themselves are divided into “segments,” with each individual segment (seg001, seg002, etc.) containing a subset of the overall dataset. This is how flight data will be delivered. The segments are numbered in their order of observation.\n",
    "\n",
    "We will use the Stage 2 Output from the [JWST data reduction pipeline](https://jwst-pipeline.readthedocs.io/en/latest/jwst/data_products/stages.html). For NIRCam, Stage 2 consists of the flat field correction, WCS/wavelength solution, and photometric calibration (counts/sec -> MJy). Note that this is specifically for NIRCam: the steps in Stage 2 change a bit depending on the instrument. The Stage 2 outputs are rougly equivalent to a “flt” file from HST.\n",
    "\n",
    "The files have the suffix ``/*calints.fits`` which contain fully calibrated images (MJy) for each individual integration. This is the one you want if you’re starting with Stage 2 and want to do your own spectral extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
